<!DOCTYPE html>
<html><head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Final project of the course &#34;Cognition and Decision making&#34; (Technion) - Louis Tungs Blog of Data Wrangling üìä üåø</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Introduction The final project of this course focuses on the prediction of choice behavior in a space of choice tasks that extends the space considered by Erev et al. (2023). The participants in Erev et al.‚Äôs study did not receive a description of the keys, and had to base their decisions on the feedback provided after each choice. The current space includes similar tasks (but with only two keys), and also considers tasks in which part of the keys are described." />
	<meta property="og:image" content=""/>
	<meta property="og:title" content="Final project of the course &#34;Cognition and Decision making&#34; (Technion)" />
<meta property="og:description" content="Introduction The final project of this course focuses on the prediction of choice behavior in a space of choice tasks that extends the space considered by Erev et al. (2023). The participants in Erev et al.‚Äôs study did not receive a description of the keys, and had to base their decisions on the feedback provided after each choice. The current space includes similar tasks (but with only two keys), and also considers tasks in which part of the keys are described." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ww11632.github.io/posts/course-work-of-congnition-and-decision-makingtechnion/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-12T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-08-12T00:00:00+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Final project of the course &#34;Cognition and Decision making&#34; (Technion)"/>
<meta name="twitter:description" content="Introduction The final project of this course focuses on the prediction of choice behavior in a space of choice tasks that extends the space considered by Erev et al. (2023). The participants in Erev et al.‚Äôs study did not receive a description of the keys, and had to base their decisions on the feedback provided after each choice. The current space includes similar tasks (but with only two keys), and also considers tasks in which part of the keys are described."/>
<script src="https://ww11632.github.io/js/feather.min.js"></script>
	
	
        <link href="https://ww11632.github.io/css/fonts.2c2227b81b1970a03e760aa2e6121cd01f87c88586803cbb282aa224720a765f.css" rel="stylesheet">
	

	
	<link rel="stylesheet" type="text/css" media="screen" href="https://ww11632.github.io/css/main.ac08a4c9714baa859217f92f051deb58df2938ec352b506df655005dcaf98cc0.css" />
		<link id="darkModeStyle" rel="stylesheet" type="text/css" href="https://ww11632.github.io/css/dark.726cd11ca6eb7c4f7d48eb420354f814e5c1b94281aaf8fd0511c1319f7f78a4.css"   />
	

	
	

	
	
	
	
</head>
<body>
        <div class="content"><header>
	<div class="main">
		<a href="https://ww11632.github.io/">Louis Tungs Blog of Data Wrangling üìä üåø</a>
	</div>
	<nav>
		
		<a href="/">Home</a>
		
		<a href="/posts">All posts</a>
		
		<a href="/tags">Tags</a>
		
		
	</nav>
	
<script async src="https://www.googletagmanager.com/gtag/js?id=G-090Q9LG5ZM"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-090Q9LG5ZM', { 'anonymize_ip': false });
}
</script>

</header>

<main>
	<article>
		<div class="title">
			<h1 class="title">Final project of the course &#34;Cognition and Decision making&#34; (Technion)</h1>
			<div class="meta">Posted on Aug 12, 2023</div>
		</div>
		

		<section class="body">
			<h2 id="introduction">Introduction</h2>
<p>The final project of this course focuses on the prediction of choice behavior in a space of choice tasks that extends the space considered by Erev et al. (2023). The participants in Erev et al.‚Äôs study did not receive a description of the keys, and had to base their decisions on the feedback provided after each choice. The current space includes similar tasks (but with only two keys), and also considers tasks in which part of the keys are described.</p>
<figure><img src="https://lh3.googleusercontent.com/pw/AIL4fc8Kl1oyZEmW96auTIjr2aldFc2UZAmVRE9LSZSbhPa-0EzSvSBPuG3dnEoSan5X-erRqvxyeuYgqONB5B6ruPE63UNkd2hsyPmboPpDoGZb4uXuo0XQakz4xWYKjvBOuQKZ6xOhkPfpixuy6wB9ek7MPW1JWrzhy7KU4TSuTxKcXXBscyn0OMVnKlR6WWTSgmDmF__fpdpTmP0oaxKwhBtc4U9Bhrr21hQuuuyHGx0Y49Ripjibk4cDwyqtwMCnvDPnrR68wxIHLOAbibAPi59kOjmZskttDNMFsmjE0EM6ZV7w6YGC85Flkk1R5KCNuxz-yKwQ9nJKKm0ji0Ig6SB223E6oh0eJ0zRtifnbgx5z3q4Ej9-sqy-MyuiD_dujO4vsKnYepo22esBXpN1sS9NMBvDI1GGkj6_AOG5quDL5dACFMUUpjRYhJ7kGkcgUc1JDCQlvC6V6vFgqcwdOWN-DAtbvuLPsk-ezHzUcp0-XnNjChpackmsR1EC_OC8_XVgdA0r9v2Ca0f2opy2BZuQCBj3YQLhEChP4-YlUnf7fo5TC4flXHJaQ8fcwZaiw1-wd0iFXxa4m6nmlFAMpukbnxH7_RUN7UUTwv4EVNbZVLuh_IJGD4R-dOD4EL3y90yoDG_D7enkEIgq9SC8KDzjJJfy3nEUvz5vXir2kkKGNSctv3ewOCO-NOrbmWPsjPfN5pcrDqq0yAkAT0uVQ6qvFO1ap6q_lP3TCW6T23M1mf8w-pyE3EeFuyRY_WwEoad78WACxCT5QhNpjleADe9ep9YZ0NG63daCnm_p9OxNgxtnlQG_P-7dtC03sIsYxDK9HNrVjL7biUb2hO9F4LxAgbZcmsV8qkEu-zK838cLB3IOWhx3PhJPtvfJw1KlroDfiTZH_ZHLtKuzaM8fkOc=w2250-h1694-s-no?authuser=0"/><figcaption>
            <h4>Figure 1 presents the instructions for the participants and the main screens in one of the tasks.</h4>
        </figcaption>
</figure>

<p>Each participant (Mturk worker) will face one task for 100 trials. Each task involves a choice between two options, and defined by Seven parameters (a1, pa1, a2, b1, pb1, b2, and Corr). Option A provides ‚Äúa1 with pa1, and a2 otherwise,‚Äù and Option B provides ‚Äúb1 with pb1, and b2 otherwise‚Äù The parameter Corr determines the correlation between the payoffs of the two options.</p>
<p>Our goal is to predict 8 statistics in each task by develop a model based on analysis of the training experiment, and then will be asked to predict the results of the test experiment:
Arate1: the proportion of A choices between trial 1 to 25
Arate 2: the proportion of A choices between trial 26 to 50
Arate 3: the proportion of A choices between trial 51 to 75
Arate 4: the proportion of A choices between trial 76 to 100
AAAbest: The proportion of A choices after a trial in which the participant chose A, and A provided the best possible payoff.
AAAnotb: The proportion of A choices after a trial in which the participant chose A, and A did not provide the best possible payoff.
ABAbest: The proportion of A choices after a trial in which the participant chose B, and A provided the best possible payoff.
ABAnotb: The proportion of A choices after a trial in which the participant chose B, and A did not provide the best possible payoff.</p>
<h2 id="explanation-of-the-variables-name-in-the-data-set">Explanation of the variables‚Äô name in the data set:</h2>
<p>ID: The participant identification code</p>
<p>Trial: Trial number (1 to 100)</p>
<p>Prob: The problem number.</p>
<p>a1: One of the two possible payoff of option A (the safer option)</p>
<p>pa1: The probability of the payoff a1</p>
<p>a2: One of the two possible payoff of option A (the safer option)</p>
<p>b1: One of the two possible payoff of option B (the riskier option)</p>
<p>pb1: The probability of the payoff b1</p>
<p>b2: One of the two possible payoff of option B (the riskier option)</p>
<p>corrab: The correlation between the random variables that determine the payoff from options A and B</p>
<p>A_label: The description of Option A (if any).</p>
<p>B_label: The description of Option B (if any).</p>
<p>Arate: 1 if A was selected, 0 otherwise</p>
<p>VA: the payoff from A</p>
<p>VB: the payoff from B</p>
<h2 id="basic-ideas-behind-my-predictions">Basic Ideas behind my predictions</h2>
<p>This task involves decision making under uncertainty. Participants are given a verbal hint, and they also learn from the feedback provided a&lt;er each round. The feedback not only shows the outcome from the choice they made, but also what would have happened had they chosen the other option.</p>
<p>This kind of task involves both learning from experience and responding to explicit cues (the verbal hint). So, the participants&rsquo; choices are likely inÔ¨Çuenced by a combination of factors, including their initial beliefs, their learning from the feedback, and their interpretation of the hint.</p>
<p>Given this context, it&rsquo;s possible that a model that incorporates cognitive features could perform well, as it could capture these diÔ¨Äerent aspects of the decision-making process. However, since the cognitive features are not directly observable, they would need to be inferred from the data, which is challenging.</p>
<p>An alternative approach would be to use a machine learning model that incorporates features based on these cognitive factors. For instance, one could create features representing the recent history of outcomes for each option, the recent history of choices, the number of times each option led to a loss, and the number of times the verbal hint was associated with each option. These features could be included in a regression or a more complex machine learning model to predict the participants&rsquo; choices.</p>
<p>Thus, I take a machine learning approach where we incorporate cognitive features.</p>
<p>However, because the provided dataset does not contain individual level data (data from each round for each participant), but only summarizes the results, it&rsquo;s not feasible to create features based on individual learning or feedback from rounds. Our feature set is limited to the task parameters provided (<code>a1</code>, <code>pa1</code>, <code>a2</code>, <code>b1</code>, <code>pb1</code>,
<code>b2</code>, <code>corr</code>).</p>
<p>Given this, we can proceed with a pure machine learning approach, using these seven task parameters to predict the eight outcome variables (<code>Arate1</code>, <code>Arate2</code>,
<code>Arate3</code>, <code>Arate4</code>, <code>AAAbest</code>, <code>AAAnotb</code>, <code>ABAbest</code>, <code>ABAnotb</code>).</p>
<p>We&rsquo;ll Ô¨Årst need to handle the missing values in the dataset. Since they are relatively few, we can replace them with the median of the respective columns. For the model, we can use a Random Forest Regressor, which can handle complex non-linear</p>
<p>relationships between the features and the target variables. We&rsquo;ll build a separate model for each of the eight statistics.</p>
<p>Let&rsquo;s start with data preprocessing and then proceed to model building. We&rsquo;ll split the data into a training set (80%) and a validation set (20%) to evaluate the performance of our models.</p>
<p>We have successfully trained a separate Random Forest model for each of the eight target variables. The performances of the models, measured by the root mean square error (RMSE) on the validation set, are as follows:</p>
<ul>
<li>&lsquo;Arate1&rsquo;: 0.1485</li>
<li>&lsquo;Arate2&rsquo;: 0.1640</li>
<li>&lsquo;Arate3&rsquo;: 0.1626</li>
<li>&lsquo;Arate4&rsquo;: 0.1794</li>
<li>&lsquo;AAAbest&rsquo;: 0.1124</li>
<li>&lsquo;AAAnotb&rsquo;: 0.1067</li>
<li>&lsquo;ABAbest&rsquo;: 0.1107</li>
<li>&lsquo;ABAnotb&rsquo;: 0.1028</li>
</ul>
<p>The RMSE values represent the average diÔ¨Äerence between the actual and predicted values in the validation set, so lower values indicate better performance.</p>
<p>These results suggest that the models can reasonably predict the eight statistics based on the seven task parameters. However, the performance could potentially be improved with more complex models or additional features. For example, if individual-level data were available, we could create features based on the learning and feedback from each round to capture the cognitive factors.</p>
<p>Here is a verbal description of the model:</p>
<p>A Random Forest model works by creating a large number of individual decision trees, each trained on a random subset of the data, and then combines their predictions to produce a Ô¨Ånal prediction. Each decision tree in the forest makes a prediction independently, and the Ô¨Ånal prediction of the Random Forest model is determined by averaging the predictions of all the trees.</p>
<p>In this case, each Random Forest model was initialized with the following</p>
<p>parameters:</p>
<ul>
<li>
<p><code>n_estimators=100</code>: This is the number of trees in the forest. Each tree is Ô¨Åt on a bootstrap sample (i.e., a sample drawn with replacement) of the data, and the predictions of all the trees are averaged to obtain the Ô¨Ånal prediction.</p>
</li>
<li>
<p><code>random_state=0</code>: This is a seed for the random number generator, used for reproducibility. With this seed, the same sequence of random numbers will be generated each time the model is run, ensuring that the results are consistent across runs.</p>
</li>
</ul>
<p>Each of these models takes as input the seven task parameters (<code>a1</code>, <code>pa1</code>, <code>a2</code>, <code>b1</code>,
<code>pb1</code>, <code>b2</code>, and <code>corrab</code>) and outputs a prediction for the corresponding target variable.</p>
<p>The Random Forest model has several advantages: it can capture complex relationships between the features and the target variable, it is robust to outliers, and it can handle both numerical and categorical features. However, it is a &ldquo;black box&rdquo; model, meaning that the process it uses to make predictions is not easily interpretable by humans.</p>
<p>In terms of performance, the model showed reasonable accuracy based on cross- validation, with Root Mean Squared Errors (RMSEs) ranging from around 0.11 to 0.20 for the diÔ¨Äerent target variables. This means that the model&rsquo;s predictions are, on average, within about 0.11 to 0.20 units of the actual values.</p>
<h2 id="link">Link</h2>
<p>Link to the <a href="https://app.noteable.io/f/a9928332-023f-4a3a-97f2-2b618d4302c7">Code</a></p>

		</section>

		<div class="post-tags">
			
			
			<nav class="nav tags">
				<ul class="tags">
					
					<li><a href="/tags/python">Python</a></li>
					
				</ul>
			</nav>
			
			
		</div>
		</article>
</main>
<footer>
  <div style="display:flex"><a class="soc" href="https://github.com/ww11632" rel="me" title="GitHub"><i data-feather="github"></i></a>
    <a class="border"></a><a class="soc" href="https://www.linkedin.com/in/lichia-t/" rel="me" title="Linkedin"><i data-feather="linkedin"></i></a>
    <a class="border"></a></div>
  <div class="footer-info">
    2023  ¬© Louis Tung |  <a
      href="https://github.com/athul/archie">Archie Theme</a> | Built with <a href="https://gohugo.io">Hugo</a>
  </div>
</footer>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'G-090Q9LG5ZM', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

<script>
  feather.replace()
</script></div>
    </body>
    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-090Q9LG5ZM"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-090Q9LG5ZM', { 'anonymize_ip': false });
}
</script>

</html>

